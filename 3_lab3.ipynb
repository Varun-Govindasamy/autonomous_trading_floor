{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from agents import Agent, Runner, trace\n",
    "from agents.mcp import MCPServerStdio\n",
    "import os\n",
    "from IPython.display import Markdown, display\n",
    "from datetime import datetime\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"command\": \"npx\",\"args\": [\"-y\", \"mcp-memory-libsql\"],\"env\": {\"LIBSQL_URL\": \"file:./memory/ed.db\"}}\n",
    "\n",
    "async with MCPServerStdio(params=params, client_session_timeout_seconds=30) as server:\n",
    "    mcp_tools = await server.list_tools()\n",
    "\n",
    "mcp_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = \"You use your entity tools as a persistent memory to store and recall information about your conversations.\"\n",
    "request = \"My name's Ed. I'm an LLM engineer. I'm teaching a course about AI Agents, including the incredible MCP protocol. \\\n",
    "MCP is a protocol for connecting agents with tools, resources and prompt templates, and makes it easy to integrate AI agents with capabilities.\"\n",
    "model = \"gpt-4.1-mini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async with MCPServerStdio(params=params, client_session_timeout_seconds=30) as mcp_server:\n",
    "    agent = Agent(name=\"agent\", instructions=instructions, model=model, mcp_servers=[mcp_server])\n",
    "    with trace(\"conversation\"):\n",
    "        result = await Runner.run(agent, request)\n",
    "    display(Markdown(result.final_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async with MCPServerStdio(params=params, client_session_timeout_seconds=30) as mcp_server:\n",
    "    agent = Agent(name=\"agent\", instructions=instructions, model=model, mcp_servers=[mcp_server])\n",
    "    with trace(\"conversation\"):\n",
    "        result = await Runner.run(agent, \"My name's Ed. What do you know about me?\")\n",
    "    display(Markdown(result.final_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = {\"BRAVE_API_KEY\": os.getenv(\"BRAVE_API_KEY\")}\n",
    "params = {\"command\": \"npx\", \"args\": [\"-y\", \"@modelcontextprotocol/server-brave-search\"], \"env\": env}\n",
    "\n",
    "async with MCPServerStdio(params=params) as server:\n",
    "    mcp_tools = await server.list_tools()\n",
    "\n",
    "mcp_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = \"You are able to search the web for information and briefly summarize the takeaways.\"\n",
    "request = f\"Please research the latest news on Amazon stock price and briefly summarize its outlook. \\\n",
    "For context, the current date is {datetime.now().strftime('%Y-%m-%d')}\"\n",
    "model = \"gpt-4o-mini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async with MCPServerStdio(params=params, client_session_timeout_seconds=30) as mcp_server:\n",
    "    agent = Agent(name=\"agent\", instructions=instructions, model=model, mcp_servers=[mcp_server])\n",
    "    with trace(\"conversation\"):\n",
    "        result = await Runner.run(agent, request)\n",
    "    display(Markdown(result.final_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "polygon_api_key = os.getenv(\"POLYGON_API_KEY\")\n",
    "if not polygon_api_key:\n",
    "    print(\"POLYGON_API_KEY is not set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreviousCloseAgg(ticker='NVDA', close=180, high=180.2, low=174.52, open=175.16, timestamp=1754337600000, volume=148174609.0, vwap=178.3605)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from polygon.rest import RESTClient\n",
    "client = RESTClient(polygon_api_key)\n",
    "client.get_previous_close_agg(\"NVDA\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from market import get_share_price\n",
    "get_share_price(\"AAPL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no rate limiting concerns!\n",
    "\n",
    "for i in range(1000):\n",
    "    get_share_price(\"AAPL\")\n",
    "get_share_price(\"AAPL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"command\": \"uv\", \"args\": [\"run\", \"market_server.py\"]}\n",
    "async with MCPServerStdio(params=params) as server:\n",
    "    mcp_tools = await server.list_tools()\n",
    "mcp_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = \"You answer questions about the stock market.\"\n",
    "request = \"What's the share price of Apple?\"\n",
    "model = \"gpt-4.o-mini\"\n",
    "\n",
    "async with MCPServerStdio(params=params) as mcp_server:\n",
    "    agent = Agent(name=\"agent\", instructions=instructions, model=model, mcp_servers=[mcp_server])\n",
    "    with trace(\"conversation\"):\n",
    "        result = await Runner.run(agent, request)\n",
    "    display(Markdown(result.final_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "params = {\"command\": \"uvx\",\n",
    "          \"args\": [\"--from\", \"git+https://github.com/polygon-io/mcp_polygon@v0.1.0\", \"mcp_polygon\"],\n",
    "          \"env\": {\"POLYGON_API_KEY\": polygon_api_key}\n",
    "          }\n",
    "async with MCPServerStdio(params=params) as server:\n",
    "    mcp_tools = await server.list_tools()\n",
    "mcp_tools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = \"You answer questions about the stock market.\"\n",
    "request = \"What's the share price of Apple? Use your get_snapshot_ticker tool to get the latest price.\"\n",
    "model = \"gpt-4.1-mini\"\n",
    "\n",
    "async with MCPServerStdio(params=params) as mcp_server:\n",
    "    agent = Agent(name=\"agent\", instructions=instructions, model=model, mcp_servers=[mcp_server])\n",
    "    with trace(\"conversation\"):\n",
    "        result = await Runner.run(agent, request)\n",
    "    display(Markdown(result.final_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "\n",
    "polygon_plan = os.getenv(\"POLYGON_PLAN\")\n",
    "is_paid_polygon = polygon_plan == \"paid\"\n",
    "is_realtime_polygon = polygon_plan == \"realtime\"\n",
    "\n",
    "if is_paid_polygon:\n",
    "    print(\"You've chosen to subscribe to the paid Polygon plan, so the code will look at prices on a 15 min delay\")\n",
    "elif is_realtime_polygon:\n",
    "    print(\"Wowzer - you've chosen to subscribe to the realtime Polygon plan, so the code will look at realtime prices\")\n",
    "else:\n",
    "    print(\"According to your .env file, you've chosen to subscribe to the free Polygon plan, so the code will look at EOD prices\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
